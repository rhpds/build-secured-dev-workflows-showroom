= Module 4: Enforce Policy and Promote Safely

== Introduction

* By this point in the workshop, you have established strong foundations of trust across the software supply chain. In Module 1, you made software composition visible by ingesting and analysing SBOMs, turning dependency risk from an assumption into evidence. In Module 2, you anchored trust in cryptographic provenance, ensuring every build artifact is signed, traceable, and verifiably produced by your CI pipeline. In Module 3, you reduced developer friction by centralising access to tools and security capabilities through *Red Hat Developer Hub*, using *GitOps* to configure authentication, plugins, and catalog discovery as a consistent, secure entry point for developers.
* One critical challenge remains: ‚ÄúHow do we prevent unverified or unsafe images from reaching staging and production?‚Äù Security controls only scale when developers do not have to think about them. If teams must manually assemble pipelines or decide when policies apply, trust quickly erodes. This is where *Software Templates*, also known as *Golden Paths*, come in. In this module, you will use *software templates* to define opinionated, secure workflows that embed the guardrails established in earlier modules by design, including SBOM generation and analysis, code and image signing, vulnerability scanning, and *Enterprise Contract* policy checks.

NOTE: Enterprise Contract is the policy engine that governs whether an application can be promoted through the delivery pipeline. It is based on the upstream open-source project link:https://conforma.dev/[*Conforma*,window=_blank], which provides policy-driven verification of software supply chain evidence such as SBOMs, vulnerability scan results, image signatures, and build attestations.


* By the end of this module, you‚Äôll see how RHADS turns trusted building blocks into repeatable, production-ready Golden Paths. Every application starts secure. Every promotion is governed. And teams move fast without bypassing trust.

---

== Step 1: Set up image vulnerability scanning

* *Red Hat Advanced Cluster Security (ACS)* provides vulnerability analysis and policy evaluation for container images. It integrates directly with container registries to scan images before they are deployed or promoted.

=== 1.1 Configure ACS - Quay Integration

* In this step, you will configure *ACS* to scan images stored in *Quay* and validate that vulnerability data can be evaluated as part of the trusted supply chain.
* In Showroom, Switch to the *ACS* tab and login using the following credentials: 
* *Username*:
+
[source, role="execute", subs="attributes"]
----
{rhacs_admin_user}
----
+
* *Password*:
+
[source, role="execute", subs="attributes"]
----
{rhacs_admin_password}
----
+
* In the *ACS console*, navigate to *Platform Configuration* ‚Üí *Integrations*
* Select Red Hat Quay.io

image::acs_quay_integration.png[acs_quay_integration,align=center"]

* Click *New Integration*.

image::acs_new_integration.png[acs_new_integration,align=center"]

* Provide the following details:
. Integration name:
+
[source, role="execute"]
----
acs_quay
----
+
. Type: Select *Registry + Scanner*
. *End Point*:
+
[source, role="execute", subs="attributes"]
----
{quay_host}
----
+
. *OAuth token*:
+
[source, role="execute", subs="attributes"]
----
{quay_admin_token}
----
+
. *Username*:
+
[source, role="execute", subs="attributes"]
----
{quay_admin_user}
----
+
. *Password*:
+
[source, role="execute", subs="attributes"]
----
{quay_admin_password}
----
+
. *Disable TLS certificate validation (insecure)*: Should be ticked
. *Create integration without testing*: Should not be ticked

image::acs_quay_inegration.png[acs_quay_inegration,align=center"]

* Click *Test* to validate the connection.

image::test_quay_connection.png[test_quay_connection,align=center"]

* Once the test succeeds, click *Save* to create the integration.
* At this point, *ACS* can securely access images stored in *Quay* and perform scans automatically.

---

=== 1.2 Scan and evaluate an image

* To confirm that scanning and policy evaluation are working end to end, you will now scan the signed image you produced in module 2.
* This next command retrieves vulnerability data for the image and returns a detailed scan report.
* In the Showroom terminal, run:

[source, role="execute", subs="attributes"]
----
roxctl image scan --insecure-skip-tls-verify=true --image={quay_host}/tssc/tekton-chains-test:latest
----

* This command evaluates the image against ACS policies and reports whether it meets deployment requirements.

[source, role="execute", subs="attributes"]
----
roxctl image check --insecure-skip-tls-verify=true --image={quay_host}/tssc/tekton-chains-test:latest
----

* Together, these checks demonstrate that:
. Container images can be scanned deterministically from the registry using ACS
. Vulnerability findings are associated with a specific image digest, not a mutable tag
. Policy evaluation can be performed programmatically as part of a CI/CD workflow
* This ensures that vulnerability scanning and policy evaluation are applied consistently across all workloads, as an integrated part of the delivery pipeline exposed through our Software Template.

---

== Step 2: Execute the Software template

===  2.1 Step introduction

* Up to this point, you‚Äôve been working in the role of a platform engineer.
* Now let‚Äôs switch personas and step into the role of a developer (User1), which you created earlier.
* As a developer, your goal is simple, get a ready-to-use development environment so you can focus on building your new feature. 
* This is exactly what Software Templates, or Golden Paths, are designed to provide.
* Under the hood, they use the link:https://backstage.spotify.com/docs/portal/core-features-and-plugins/scaffolder[*Backstage scaffolder*,window=_blank] to automate the creation of repositories, configuration, and CI/CD resources based on platform-approved patterns, as you‚Äôll see in the next section.

---

===  2.2 Open Red Hat Developer Hub in Incognito Mode

* Open RHDH in a Private/Incognito window using the link:{developer_hub_url}[*RHDH URL*,window=_blank] 

* *Username*:

[source, role="execute"]
----
user1
----

* *Password*:

[source, role="execute" ]
----
{password}
----

WARNING: If you do not use Private/Incognito window you will be logged in using the admin credentials and will not be
able to impersonate a developer.

---

===  2.3 Run the Software Template

. Click on Home in the left navigation menu
. From the RHDH home page, scroll down until you see the Explore Templates section.
. At the moment, only one template is available, but in real environments, platform teams typically provide multiple Golden Paths for different application types and technology stacks.
. Click on the link: ‚ÄúSecuring a Quarkus Service Software Supply Chain (Tekton)‚Äù.

image::select_software_template.png[select_software_template,align="center"]

* You will be guided through a four-step, wizard-style form to collect the required inputs.
* Instead of raising tickets and waiting for manual setup, this workflow applies platform standards automatically, as defined by the template.
* In the first form, you are prompted to enter application-specific parameters.
* Default values are already provided by the template, so keep the defaults and click *Next*.

image::software_template_step1.png[software_template_step1,align="center"]

* The second form provides container image registry details.
* In this workshop, container images are pushed to *Quay.io*.
* The required values are pre-filled, so click *Next* to continue.

image::software_template_Step2.png[software_template_Step2,align="center"]

* In the third form, you configure the source code repository, which is *GitLab* in this environment.
. Set *Verify Commits* to *Enabled*. This enforces commit signature verification in the pipeline, ensuring that only signed and trusted commits are accepted during the build process.
. Leave the remaining values as provided by the template.
* Click *Review* to proceed.

image::software_template_step3.png[software_template_step3,align="center"]

* You will now see a summary of all the parameters that will be passed to the *scaffolder* when executing the template steps.
* These  values are used to:
. Create the Git repository and application skeleton
. Configure CI pipelines
. Register the component in the RHDH Software Catalog
* Review the values, then click *Create* to start the scaffolding process.

image::software_template_review.png[software_template_review,align="center"]

* After a short time, the scaffolder workflow will complete and you will see a confirmation screen with green checkmarks indicating each step has succeeded.
* Click *Open Component in Catalog* to view your newly created application in the Developer Hub.

image::open_component_in_catalog.png[open_component_in_catalog,align="center"]

---

=== *`Optional Deep Dive üîç:`* Understanding Software Templates

* Software Templates are the primary mechanism used by *Red Hat Developer Hub* to expose Golden Paths to development teams.
* Templates are defined using YAML and rendered as rich, validated forms in the Red Hat Developer Hub UI. Developers interact with a simple form. Behind the scenes, the platform does all the heavy lifting.
* This YAML is processed by the *Scaffolder*, *RHDH*'s templating engine, which executes the steps outlined in the template.
* This ensures that every new service is created in a standerdize, automated , self service way.
* Let‚Äôs examine the structure of a template using 

=== Software Template YAML Structure

* At a basic level, the Template Entity resembles a Kubernetes Custom Resource.
* Where the Template Entity differs is that it contains additional fields: 
. *Header*: Here, you provide essential information about the template.
. *Parameters*: This section is for gathering inputs from the user.
. *Steps*: In this section, you define the actions to be executed by the *Scaffolder*.
. *Output*: This section is optional and allows you to provide details about the tasks performed by the *Scaffolder*.
* Let‚Äôs examine each in more detail.

---

=== Template Header

* The header section is mandatory for every template.
* The *Component* card on the *Create Component* page is displayed based on the details in the Header section.
* For example, this is the header of the link:${gitlab_url}/rhdh/build-secured-dev-workflows-idp-configuration/-/blob/main/scaffolder-templates/quarkus-stssc-template/template.yaml[Software Template,,window=_blank] you will execute in the coming steps:

[source, yaml]
----
apiVersion: scaffolder.backstage.io/v1beta3
kind: Template
metadata:
  name: quarkus-stssc-template
  title: Securing a Quarkus Service Software Supply Chain (Tekton)
  description: Create a Quarkus Service built with Red Hat Trusted Application Pipeline on Tekton
  tags:
    - recommended
    - java
    - quarkus
    - maven
spec:
  owner: tssc
  type: service
  # other fields removed for brevity
----

* The Software Template card is displayed in *RHDH* based on the header information, including the title, description, and tags.

---

===  Template Parameters

* Within the template, the *spec.parameters* field is used to generate the form.
* You can choose to break up the parameter prompting into *form steps* or collect all the parameters in a single step.
* This allows RHDH to generate a wizard like step by step process
* In other words the parameters property is an array, each entry in the array is a *form step*.
* Each form step must specify a *title*, which *properties* it will ask from the user, and if any of them is *required*.
* Following is snippet of te properties section of the Software template you'll execute in the following steps.
* RHDH renders as three steps, each with a seperate form:
. Provide Information for Application
. Provide Image Registry Information
. Application Repository Information
+
[source, yaml]
----
parameters:
    # Parameters can be spread across multiple forms/pages, each
    # with their own titles and set of parameters
    - title: Provide Information for Application
      required:
        - name
        - javaPackageName
      properties:
        name:
          title: Name
          type: string
          description: Unique name of the component
          default: my-quarkus-tkn
          ui:field: EntityNamePicker
          maxLength: 23
         # other fields removed for brevity
    - title: Provide Image Registry Information
      required:
        - imageHost
        - imageOrganization
      properties:
        imageHost:
          title: Image Registry
          type: string
          default: Quay
          enum:
            - Quay
        imageOrganization:
          title: Organization
          type: string
          description: Name of the Quay Organization
          default: tssc
          ui:readonly: true
    - title: Application Repository Information
      required:
        - repoHost
        - repoOwner
        - repoVerifyCommits
      properties:
        repoHost:
          title: Source Repo
          type: string
          default: GitLab
          enum:
            - GitLab
        # other fields removed for brevity
----

---

=== Template Steps

* Steps define the actions that are performed by the *Scaffolder*  during its execution.
* They are executed sequentially as defined in the template.
* Each step utilizes actions for tasks such as publishing to a Gitlab repository (publish:gitlab) or registering a component in the catalog (catalog:register).
* RHDH offers various built-in actions, and you can define custom actions as well.
+
[source, yaml]
----
  steps:
    - id: fetch-provision-data
      name: Fetch Provision Data
      action: catalog:fetch
      input:
        entityRef: component:default/provisioning-data
 	# other steps removed for brevity
    
    - id: publish-gitlab-source
      name: Publish
      action: publish:gitlab
      input:
        repoUrl: 'gitlab-gitlab.${{ steps["fetch-provision-data"].output.entity.metadata.labels["ocp-apps-domain"] }}?owner=${{
          parameters.repoOwner }}&repo=${{parameters.name}}'
        repoVisibility: public
    # other steps removed for brevity
   
    - id: register-source
      name: Register Source
      action: catalog:register
      input:
        repoContentsUrl: ${{ steps['publish-gitlab-source'].output.repoContentsUrl }}
        catalogInfoPath: '/catalog-info.yaml'
    # other steps removed for brevity
----
+ 
* Notice how the parameters are referenced in the input of the steps? 
* Another point of note is that subsequent steps can access output from prior steps.
* To see the available actions in *RHDH* and understand their input and output parameters, go to the *Create Content* page by selecting *Create* from the left sidebar menu.
* Next, open the *Kebab* menu at the top right of the *Create Content* page and choose *Installed Actions*.

=== Template Output

* The spec.output can be used to display useful information such as:
. Links to newly created Components
. Source Code Repository links
. Links to Git Merge Requests that are needed etc

[source, yaml]
----
output:
    links:
      - title: Source Repository
        url: ${{ steps['publish-gitlab-source'].output.remoteUrl }}
      - title: GitOps Repository
        url: ${{ steps['publish-gitlab-gitops'].output.remoteUrl }}
      - title: Open Component in catalog
        icon: catalog
        entityRef: ${{ steps['register-source'].output.entityRef }}
      - title: Open GitOps Resource in catalog
        icon: catalog
        entityRef: ${{ steps['register-gitops'].output.entityRef }}
----

---

== Step 3: Explore Your Quarkus Application

* Evan to provide details here

---

== Step 4: Prepare Developer and Pipeline Trust Foundations

* Before you start modifying code, you need to configure Git commit signing in OpenShift Dev Spaces.
* link:https://developers.redhat.com/products/openshift-dev-spaces[*OpenShift Dev Spaces*,window=_blank] provides cloud-hosted development environments that run inside the cluster. These environments are defined declaratively using link:https://devfile.io/[*Devfiles*,window=_blank], which describe the tools, configuration, and lifecycle behaviour of a developer workspace.
*  You also need to ensure the CI pipelines have the credentials required to authenticate with external systems during the build and verification stages.

=== 4.1 Create the tas-git-config ConfigMap

* In this step, you will configure *Dev Spaces* so that every developer workspace automatically inherits the information required for OIDC-based Git commit signing, without manual setup.

* First, create a new ConfigMap in the openshift-devspaces namespace:

[source, role="execute", subs="attributes"]
----
cat << 'EOF' | oc apply -n openshift-devspaces -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: tas-git-config
  annotations:
    controller.devfile.io/mount-as: env
  labels:
    app.kubernetes.io/part-of: che.eclipse.org
    app.kubernetes.io/component: workspaces-config
data:
  TAS_FULCIO_URL: "{tas_fulcio_url}"
  TAS_REKOR_URL: "{tas_rekor_url}"
  TAS_ISSUER_URL: "https://sso.{openshift_cluster_ingress_domain}/realms/sso"
  TAS_CLIENT_ID: "trusted-artifact-signer"
EOF
----

* This ConfigMap defines the endpoints and identity configuration required by *gitsign*, the tool used to perform keyless Git commit signing via *RHTAS*.

NOTE: The label app.kubernetes.io/component=workspaces-config instructs Dev Spaces to inject these values into every developer workspace as environment variables.

---

=== 4.2 *`Optional Deep Dive üîç:`* Development Environment as Code with Devfiles

* The concept of *Development Environment as Code* represents a significant shift in the way we set up and manage development environments. 
* By treating these configurations as code, developers can leverage automation, apply version control, and ensure consistency across various setups. 
* This approach simplifies the complex process of configuring individual environments and aligns it with modern DevOps practices.
* At the heart of this paradigm is the *Devfile*, a powerful YAML configuration file used by **OpenShift Dev Spaces**. 
* *Devfiles* act as comprehensive blueprints for setting up development environments, defining everything from runtime environments to the necessary tools and commands needed for a project.

=== Anatomy of a Devfile

==== Projects (Optional)

* The *Projects* section is used to specify source code repositories that are essential for the development environment. 
* It includes details like the repository URL and the specific branch, tag, or commit to be used, ensuring that the *workspace* is pre-populated with the correct code version upon initialization.

==== Components: 

* *Components* are the building blocks of the development environment. The can be of type:
. *Container*: Defines the container image containing the runtime environment, development tools, and dependencies.
. *Kubernetes/OpenShift Resources*: Incorporates Kubernetes or OpenShift-specific resources such as Routes and BuildConfigs into the workspace.
. *Volume*: Provides persistent storage necessary for certain data within the development environment.
. *Plugin*: Extends the capabilities of the development environment by adding IDE features or integrating additional tools and services.

==== Commands (Optional): 

* The **Commands** section outlines specific actions that can be executed within the development environment, such as build, run, and test commands. 
* These *commands* are defined to automate tasks and facilitate a consistent development workflow across different environments. 
* Each *command* can specify a working directory, an associated container, and the actual command line to execute.

==== Events (Optional): 

* The *Events* section in a *devfile* handles the lifecycle events of the workspace, such as pre-start, post-start, pre-stop, and post-stop events.
* These events trigger specific commands at different stages of the workspace lifecycle, enabling the setup or teardown of services and tools necessary for the development process.
* This mechanism ensures that certain tasks are automatically handled at the appropriate times, enhancing both the efficiency and reliability of the development environment.

image::devfile_anatomy.png[]

* Now it‚Äôs time to try this out hands-on. In this module, you‚Äôll experience firsthand how *OpenShift Dev Spaces* streamlines the process of joining a new project.

---

=== 4.3 Log Back in to GitLab Update the Devfile 

* If you are not already logged in to *RHBK*, click the *Gitlab* tab in the Showroom and log in using:

* *Username*:

[source, role="execute", subs="attributes"]
----
{gitlab_root_user}
----

* *Password*:

[source, role="execute", subs="attributes"]
----
{gitlab_root_password}
----

---

=== 4.4 Update the Devfile 

. At the top left click on Gitlab Home
+
image::gitlab_home_page.png[gitlab_home_page,align="center"]
+
. Select the repository "development / my-quarkus-tkn"
+
image::my-quarkus-tkn_repo.png[gitlab_home_page,align="center"]
+
. Select the the file *devfile.yaml*
+
image::select_devfile.png[select_devfile,align="center"]
+
. Select *Edit* > *Edit single file*.
+
image::devfile_single_edit.png[devfile_single_edit,align="center"]
+
. In devfile.yaml, locate and uncomment the *attribures* section using `CMD + /` (Mac) or `CTRL + /` (Windows/Linux) as shown below: 
** These attributes allow configuration from the ConfigMap you created earlier to be injected into your workspace in OpenShift Dev Spaces.
+
image::dev_tools_atributes.png[dev_tools_atributes,align="center"]
+
. Next, under the commands section, uncomment the *init-git-config* command using using `CMD + /` (Mac) or `CTRL + /` (Windows/Linux) as shown below:  
** This command updates the Git configuration for the current workspace session using the injected environment variables, enabling commit signing.
+
image::init_git_config_command.png[init_git_config_command,align="center"]
+
. Finally, under the events section, uncomment the postStart event using CMD + / (Mac) or CTRL + / (Windows/Linux). 
** This *post-start* event automatically triggers the *init-git-config* command as soon as the workspace starts.
+
image::poststart_Event.png[poststart_Event.png,align="center"]
+
. Scroll down and enter a commit message: 
+
[source, role="execute"]
----
feat: Update Devfile Configuration 
----
+
. Click *Commit Changes* 

---

=== 4.5 Configure pipeline authentication secrets

* Before executing the software template, the CI pipeline must be able to authenticate to the systems it interacts with.
* All application pipelines in this workshop run in the tssc-app-ci namespace. Any credentials required by the pipeline must be available there as Kubernetes Secrets.
* In this step, you will create two  secrets required by the pipeline:
. *tpa-secret*: Credentials for uploading SBOMs to *Red Hat Trusted Profile Analyzer (RHTPA)*
. *gitlab-auth-secret*: Credentials for authenticating to GitLab when creating repositories and interacting with source code
* Run the following command to set the TPA_SERVER_URL
+
[source,role="execute"]
----
export TPA_SERVER_URL="https://$(oc get route -l app.kubernetes.io/component=server -n tssc-tpa -o json \
  | jq -r '.items[0].spec.host')"
----
+
* Then run this command to create the secret *tpa-secret*:
+
[source,role="execute"]
----
envsubst < ~/lab-assets/tpa-secret.yml | oc apply -n tssc-app-ci -f -
----
+
* Next, create the GitLab authentication secret
. First, retrieve the GitLab personal access token:
+
[source,role="execute"]
----
export GITLAB_TOKEN=$(oc get secret root-user-personal-token -n gitlab -o jsonpath='{.data.token}' | base64 -d)
----
+
. Next, create the *gitlab-auth-secret* secret:
+
[source,role="execute"]
----
envsubst < ~/lab-assets/gitlab-auth-secret.yml | oc apply -n tssc-app-ci -f -
----
+
* In the next step, you will make a small code change from within OpenShift Dev Spaces and commit it to Git. 
* This commit will be automatically signed using your OIDC identity.

---

== Step 5: Sign Your Code and Enter the Trusted Supply Chain

* In this step, you will make a small code change from within OpenShift Dev Spaces and commit it to Git. The commit will be signed automatically using your OIDC identity, and this signed commit will trigger the CI pipeline. 
* Your trusted identity is now carried forward into the build, verification, and promotion stages of the software supply chain.

=== 5.1 From Red Hat Developer Hub (Incognito Mode)

. From your incognito browser session, navigate to Red Hat Developer Hub.
. Click the link for *OpenShift Dev Spaces*. This will open your cloud-based development environment in a separate browser window, providing you with a fully configured workspace for you to implement your code change.
. * *OpenShift Dev Spaces* then begins creating your workspace.
* After waiting a few minutes for *OpenShift Dev Spaces* to finish setting up your workspace, you're presented with your IDE.
* You click the button *Yes, I trust the authors*.
+
image::96_Trust_Authors.png[]
+

=== 5.2 Verify Git Signing Configuration in OpenShift Dev Spaces

* Before committing any code, you will first verify that Git commit signing has been correctly configured in your OpenShift Dev Spaces workspace.
* As you will see, the development environment has already been configured to use gitsign based on the configuration applied earlier in our Devfile.
* To confirm this, open the VS Code terminal inside your workspace and run the following command:
+
[source, role="execute"]
----
git config --global --list
----

NOTE: You may be prompted by your browser to allow paste access into the terminal. If so, approve the prompt to proceed.

image::94_Gitsign_Git_Global_Config.png[]

=== 5.3 Apply a simple code change

* To see code sigiing in action we are goinf to apply a simple change, write a comment in the index document.
.	Navigate to Docs folder and select the file index.md.
. Add the following line at the bottom of the document
+
[source, role="execute"]
----
# Test code siging
----
+
image::97_Index_Markdown_Updated.png[]
+
* Open the IDE terminal, click on the *Hamburger button* (three horizontal bars) on the top left of your screen and select *Terminal -> New Terminal*
+
image::98_Terminal_Menu.png[]
+
* To begin commiting your code to the repository, run the following command to add your changes to staging and commiting your changes:

[source, role="execute"]
----
git add .
git commit -m "feat: updated configuration with secure signing"
----
+
* You will notice that you receive an error message that states *error opening browser: exec: "xdg-open": executable file not found in $PATH*.  This is because our *VS Code* terminal is trying to open a browser window to obtain your credentials for signing but is unable to as it is running as a container.
* However, Gitsign allows you to provide your signing credentials by copying and pasting the url it outputs into a separate browser window.
* Copy and paste the url into a new browser tab/window and hit enter.
+
image::90_Gitsign_Commit_Message.png[]
+
 The browser will prompt you for your credentials.  Enter `{user}` for the username and `{password}` for the password.

image::91_Gitsign_Credentials_Prompt.png[]

* You will then be redirected to another page that will present a verification code.  Copy this code into your clipboard.

image::92_Gitsign_Verification_Code.png[]

* Return to *Dev Spaces* and paste this code into the waiting prompt in the *VS Code* terminal.
+
[source, role="execute"]
----
Enter verification code:
----
+
NOTE: Once you've pasted the code, depending on your browser, you may be presented with a popup to allow paste functionality in Devspaces.  Click *Allow* and then hit *Enter*.  If no popup appears, just hit *Enter*.
* If successful, you should receive a successful commit message:
+
image::93_Gitsign_Commit_Signed.png[]
+
* Push the code to the repository with the below command:
+
[source, role="execute"]
----
git push origin main
----
+
* This action sets the build pipeline into motion.
* Switch back to the *Developer Hub* and select the *CI tab* from the top menu, note that the pipeline execution is in progress. This may take a few minutes to complete.

image::112_secure_pipeline_in_progress.png[]

* In the meantime let's explore the different tasks in this pipeline.

image::113_Jenkins_Secure_Build_Pipeline.png[]

=== Task 1: Verify Commit

* "The first task after cloning our git repo, is ensuring the source code modifications were made by a trusted source.
* "This task will only succeed if it can verify a trusted signature on the last commit that triggered the pipeline. This is the signature we provided using *GitSign* when we committed the code from *Dev Spaces*."
* Click on the task *verify-commit* and expand the logs section.

image::114_Jenkins_Click_On_Verify_Commit.png[]

* "Here in the log, you can see that we successfully validated the signature for the user who made the last code change.‚Äù
* "The *verify-commit* task executes the command link:https://git-scm.com/book/en/v2/Git-Tools-Signing-Your-Work[*git verify-commit*,window=_blank] to verify that the signature is valid, before the pipeline moves to the next task." you point out.

image::115_Jenkins__Verify_Commit_Log.png[]

== Task 2: Scan Source

* "After we package the code, running a static analysis to detect any potential bugs or code style violations is a good idea."
* The task called *scan* task,  utilizes a tool called link:https://www.sonarsource.com/products/sonarqube[*SonarQube*,window=_blank] to analyze the source code and provide reports based on its quality.
* "We can view the scan results from the pipeline logs as we did before, or we could log in to *SonarQube* to get an in-depth report."
* "Let's look at the *SonarQube* report this time," you decide.
* To access *SonarQube*, you use the following https://sonarqube-sonarqube.{OPENSHIFT_CLUSTER_INGRESS_DOMAIN}[*URL*,window=_blank]  and log in with your credentials, **username:** `{adminuser}` and **password**: `{password}`.
* You click on the project link in the *SonarQube* Dashboard.
* "Good news! Our application has passed the validation test by *SonarQube*" .

image::54_SonarQube_Dashboard.png[]

== Task 3: Build and Sign Image

* "The *build-sign-image* task is responsible for building a container image based on your verified source code. It then attests the image and generates the *Software Bill of Materials (SBOM)* we discussed earlier."
* "This *SBOM* is then pushed to our *Red Hat Quay* registry upon successful completion of this task
* The SBOM is then stored in the image registry, alongside your container image.‚Äù

image::116_Jenkins_Build_Sign_Image.png[]

* Switch to the image registry tab, note that the generated attestation, signature, and SBOM files are sitting side-by-side with the resulting container image produced by the pipeline in the registry.

image::59_Generated_Artifacts_Registery.png[]


=== Task 4: Upload SBOM to Repository

* Once the *SBOM* has been generated, the next step is to upload it to your organization's CycloneDX repository. 
* "The *SBOM* now sits in a single catalogue that every team can query, storing each SBOM with its build number and signature gives auditors a clear trail that proves provenance, verifies licensing obligations, and shows when components were updated or removed," you explain.

image::119_Jenkins_Upload_SBOM_To_CycloneDX.png[]

=== Task 5: Upload SBOM to TPA

* In parallel, the *SBOM* is uploaded to Trusted Profile Analyzer (TPA).  We do this to turn the raw SBOM into actionable information.  For example, TPA can identify dependencies in your image that are targets of known Common Vulnerabilities and Exploits (CVEs).  These CVE's can be viewed on the Trusted Profile Analyzer console for the specific *SBOM* uploaded.

image::120_Jenkins_Upload_SBOM_To_TPA.png[]

* To access *Trusted Profile Analyzer (TPA)*, you use the following https://console-trusted-profile-analyzer.{OPENSHIFT_CLUSTER_INGRESS_DOMAIN}[*URL*,window=_blank] and log in with your credentials, **username**: `{adminuser}` and **password**: `{password}`.

* "You can view the vulnerabilities and recommended remediation inside the SBOM we just uploaded to **Trusted Profile Analyzer (TPA)**," you explain, clicking **Search** in the left navigation menu.

image::121_Search_TPA.png[]

* In the results table, click the **secured-app** link at the top. "The first entry in the list is the SBOM for our **secured-app** application," you point out.

image::122_Results_TPA.png[]

* You switch to the **Dependency Analytics Report** tab as ypu explain, "This view lists every discovered security issue and the remediation that Trusted Profile Analyzer suggests."

image::123_Dependency_Analytics_TPA.png[]

=== Task 6: ACS Image Check

* You switch back to the pipeline view as you explain: "*ACS* doesn't stop at scanning; it can also assess whether the image adheres to predefined rules by performing an image check".
* "The *image-scan-check* task evaluates the container image against policies and compliance standards. This includes not running as root, using approved base images, or avoiding prohibited software packages, for example."

image::118_Jenkins_ACS_Image_Check_Task.png[]

=== Task 7: Image Scan

* "The *acs-image-scan* task performs an image scan to identify known vulnerabilities within the container image. It compares the image components against known vulnerability databases, uncovering any CVEs (Common Vulnerabilities and Exposures) that might compromise the container."

image::117_Jenkins_ACS_Image_Scan_Task.png[]




== Step 1: Analyse the Dev Build (Security Audit)

Before promoting anything, review the evidence produced by the pipeline in Module 3.
This evidence is what the Enterprise Contract will later enforce.

1.1 Inspect the Pipeline Run
	1.	Open Red Hat Developer Hub (RHDH).
	2.	Select your component (for example, my-secure-app) from the Catalog.
	3.	Click the CI tab and locate the pipeline run triggered in Module 3.
The status should be Succeeded.


‚∏ª

1.2 Review the Security Artifacts

Expand the pipeline run and highlight the following steps:
	‚Ä¢	acs-image-scan
The image was scanned by Red Hat Advanced Cluster Security (RHACS) during the build.
	‚Ä¢	sbom-json / upload-sbom
An SBOM was generated and uploaded to RHTPA (Module 1).
	‚Ä¢	sign-image
The image was signed using an OIDC identity and recorded in Rekor (Module 2).

Consultant deep dive ‚Äì the invisible security officer:
The developer did not run scans, manage keys, or make security decisions.
The pipeline definition, owned by the platform team, enforced these controls automatically.
If a critical policy violation had occurred, the pipeline would have failed before the image was ever published.

‚∏ª

Step 2: Trigger the Release (Developer Action)

Now simulate a developer indicating that the code is ready for release.

2.1 Access the Source Repository
	1.	In RHDH, stay on the component Overview tab.
	2.	Click View Source to open the GitLab repository.
	3.	Log in to GitLab if prompted.

‚∏ª

2.2 Create a Release Tag
	1.	In GitLab, navigate to Code ‚Üí Tags (or use the + menu).
	2.	Click New Tag.
	3.	Set:
	‚Ä¢	Tag name: v1.0 (or prod-rc-1)
	‚Ä¢	Create from: main
	4.	Click Create tag.

What just happened:
The Golden Path template configured a webhook that treats tags differently from commits.
Creating a tag triggers a release pipeline, not the standard development pipeline.

‚∏ª

Step 3: Enterprise Contract Gate (Operations View)

Return to RHDH to observe automated policy enforcement.

3.1 Observe the Release Pipeline
	1.	Navigate back to the CI tab.
	2.	A new PipelineRun should appear (for example, release-pipeline-‚Ä¶).
	3.	Click into the pipeline to follow its progress.

‚∏ª

3.2 Inspect the verify-enterprise-contract Task

This is the critical control point.
	1.	Wait for the verify-enterprise-contract task to reach Succeeded.
	2.	Click the task and review the logs.

What EC validates:
	1.	Provenance: Was the image built by a trusted pipeline?
	2.	Identity: Does the signature match the expected OIDC issuer and subject?
	3.	Integrity: Is the SLSA attestation valid and untampered?



‚∏ª

Step 4: GitOps Promotion (Platform View)

Once policy passes, promotion happens automatically through GitOps.

4.1 Verify Argo CD State
	1.	In RHDH, open the CD tab.
	2.	Observe the Argo CD applications (for example, my-app-dev, my-app-stage).
	3.	Confirm that my-app-stage is syncing or has synced to the new image tag.

‚∏ª

4.2 Verify the Application Topology
	1.	Click the Topology tab in RHDH.
	2.	Confirm the application is now running in the Staging namespace.

‚∏ª

Troubleshooting: Enterprise Contract Failure

If the verify-enterprise-contract task fails:
	1.	Review the task logs.
	2.	Common cause: OIDC issuer or subject mismatch.
	3.	Resolution: Update the Enterprise Contract policy to match the signing identity configured in Module 2.

‚∏ª

Module 4 Takeaway
	‚Ä¢	In this module, you addressed the final customer challenge: enforcing policy consistently without slowing delivery.
	‚Ä¢	As a consultant, you demonstrated automated governance using Enterprise Contract and GitOps-based promotion.
	‚Ä¢	For customers, this means releases are approved by policy, not process. No spreadsheets, no manual gates, no trust assumptions.
	‚Ä¢	For technical sellers, this completes the story: RHADS enforces trust from commit to production, automatically and at scale.

Final customer message:
‚ÄúWith RHADS, you move fast because the platform verifies trust for you, and you stay safe because policy guarantees only verified software reaches production.‚Äù