= Module 4: Enforce Policy and Promote Safely

== Introduction

* By this point in the workshop, you have established strong foundations of trust across the software supply chain.
* In Module 1, you made software composition visible by ingesting and analysing SBOMs, turning dependency risk from an assumption into evidence.
* In Module 2, you anchored trust in cryptographic provenance, ensuring every build artifact is signed, traceable, and verifiably produced by your CI pipeline.
* In Module 3, you reduced developer friction by centralising access to tools and security capabilities through *Red Hat Developer Hub*. Authentication, plugins, and catalog discovery were configured using GitOps to create a consistent, secure entry point for developers.
* One critical challenge remains: ‚ÄúHow do we prevent unverified or unsafe images from reaching staging and production?‚Äù
* Security controls only scale when developers do not have to think about them. If teams must manually assemble pipelines, remember which checks to enable, or decide when policies apply, trust quickly erodes.
* This is where Software Templates (Golden Paths) come in.
* In this module, you will use software templates to define opinionated, secure workflows.
* These templates embed the guardrails established in earlier modules by design, including SBOM generation and analysis, code and image signing, vulnerability scanning, and Enterprise Contract policy checks.

NOTE: Enterprise Contract is the policy engine that governs whether an application can be promoted through the delivery pipeline. It is based on the upstream open-source project link:https://conforma.dev/[*Conforma*,window=_blank], which provides policy-driven verification of software supply chain evidence such as SBOMs, vulnerability scan results, image signatures, and build attestations.

* Developers consume a single, self-service workflow. Security teams gain consistent enforcement. Platform teams retain control over how software is built, verified, and promoted.
* By the end of this module, you‚Äôll see how RHADS turns trusted building blocks into repeatable, production-ready Golden Paths. Every application starts secure. Every promotion is governed. And teams move fast without bypassing trust.

---

== Step 1: Set up image vulnerability scanning

* *Red Hat Advanced Cluster Security (ACS)* provides vulnerability analysis and policy evaluation for container images. It integrates directly with container registries to scan images before they are deployed or promoted.

=== 1.1 Configure ACS - Quay Integration

* In this step, you will configure *ACS* to scan images stored in *Quay* and validate that vulnerability data can be evaluated as part of the trusted supply chain.
* In Showroom, Switch to the *ACS* tab and login using the following credentials: 
* *Username*:
+
[source, role="execute", subs="attributes"]
----
{rhacs_admin_user}
----
+
* *Password*:
+
[source, role="execute", subs="attributes"]
----
{rhacs_admin_password}
----
+
* In the *ACS console*, navigate to *Platform Configuration* ‚Üí *Integrations*
* Select Red Hat Quay.io

image::acs_quay_integration.png[acs_quay_integration,align=center"]

* Click *New Integration*.

image::acs_new_integration.png[acs_new_integration,align=center"]

* Provide the following details:
. Integration name:
+
[source, role="execute"]
----
acs_quay
----
+
. Type: Select *Registry + Scanner*
. *End Point*:
+
[source, role="execute", subs="attributes"]
----
{quay_host}
----
+
. *OAuth token*:
+
[source, role="execute", subs="attributes"]
----
{quay_admin_token}
----
+
. *Username*:
+
[source, role="execute", subs="attributes"]
----
{quay_admin_user}
----
+
. *Password*:
+
[source, role="execute", subs="attributes"]
----
{quay_admin_password}
----
+
. *Disable TLS certificate validation (insecure)*: Should be ticked
. *Create integration without testing*: Should not be ticked

image::acs_quay_inegration.png[acs_quay_inegration,align=center"]

* Click *Test* to validate the connection.

image::test_quay_connection.png[test_quay_connection,align=center"]

* Once the test succeeds, click *Save* to create the integration.
* At this point, *ACS* can securely access images stored in *Quay* and perform scans automatically.

---

=== 1.2 Scan and evaluate an image

* To confirm that scanning and policy evaluation are working end to end, you will now scan the signed image you produced in module 2.
* This next command retrieves vulnerability data for the image and returns a detailed scan report.
* In the Showroom terminal, run:

[source, role="execute", subs="attributes"]
----
roxctl image scan --insecure-skip-tls-verify=true --image={quay_host}/tssc/tekton-chains-test:latest
----

* This command evaluates the image against ACS policies and reports whether it meets deployment requirements.

[source, role="execute", subs="attributes"]
----
roxctl image check --insecure-skip-tls-verify=true --image={quay_host}/tssc/tekton-chains-test:latest
----

* Together, these checks demonstrate that:
. Container images can be scanned deterministically from the registry using ACS
. Vulnerability findings are associated with a specific image digest, not a mutable tag
. Policy evaluation can be performed programmatically as part of a CI/CD workflow
* This ensures that vulnerability scanning and policy evaluation are applied consistently across all workloads, as an integrated part of the delivery pipeline exposed through our Software Template.

---

== Step 2: Execute the Software template

===  2.1 Step introduction

* Up to this point, you‚Äôve been working in the role of a platform engineer.
* Now let‚Äôs switch personas and step into the role of a developer (User1), which you created earlier.
* As a developer, your goal is simple, get a ready-to-use development environment so you can focus on building your new feature. 
* This is exactly what Software Templates, or Golden Paths, are designed to provide.
* Under the hood, they use the link:https://backstage.spotify.com/docs/portal/core-features-and-plugins/scaffolder[*Backstage scaffolder*,window=_blank] to automate the creation of repositories, configuration, and CI/CD resources based on platform-approved patterns, as you‚Äôll see in the next section.

---

===  2.2 Open Red Hat Developer Hub in Incognito Mode

* Open RHDH in a Private/Incognito window using the link:{developer_hub_url}[*RHDH URL*,window=_blank] 

* *Username*:

[source, role="execute"]
----
user1
----

* *Password*:

[source, role="execute" ]
----
{password}
----

WARNING: If you do not use Private/Incognito window you will be logged in using the admin credentials and will not be
able to impersonate a developer.

---

===  2.3 Run the Software Template

. Click on Home in the left navigation menu
. From the RHDH home page, scroll down until you see the Explore Templates section.
. At the moment, only one template is available, but in real environments, platform teams typically provide multiple Golden Paths for different application types and technology stacks.
. Click on the link: ‚ÄúSecuring a Quarkus Service Software Supply Chain (Tekton)‚Äù.

image::select_software_template.png[select_software_template,align="center"]

* You will be guided through a four-step, wizard-style form to collect the required inputs.
* Instead of raising tickets and waiting for manual setup, this workflow applies platform standards automatically, as defined by the template.
* In the first form, you are prompted to enter application-specific parameters.
* Default values are already provided by the template, so keep the defaults and click *Next*.

image::software_template_step1.png[software_template_step1,align="center"]

* The second form provides container image registry details.
* In this workshop, container images are pushed to *Quay.io*.
* The required values are pre-filled, so click *Next* to continue.

image::software_template_Step2.png[software_template_Step2,align="center"]

* In the third form, you configure the source code repository, which is *GitLab* in this environment.
. Set *Verify Commits* to *Enabled*. This enforces commit signature verification in the pipeline, ensuring that only signed and trusted commits are accepted during the build process.
. Leave the remaining values as provided by the template.
* Click *Review* to proceed.

image::software_template_step3.png[software_template_step3,align="center"]

* You will now see a summary of all the parameters that will be passed to the *scaffolder* when executing the template steps.
* These  values are used to:
. Create the Git repository and application skeleton
. Configure CI pipelines
. Register the component in the RHDH Software Catalog
* Review the values, then click *Create* to start the scaffolding process.

image::software_template_review.png[software_template_review,align="center"]

* After a short time, the scaffolder workflow will complete and you will see a confirmation screen with green checkmarks indicating each step has succeeded.
* Click *Open Component in Catalog* to view your newly created application in the Developer Hub.

image::open_component_in_catalog.png[open_component_in_catalog,align="center"]

---

=== *`Optional Deep Dive üîç:`* Understanding Software Templates

* Software Templates are the primary mechanism used by *Red Hat Developer Hub* to expose Golden Paths to development teams.
* Templates are defined using YAML and rendered as rich, validated forms in the Red Hat Developer Hub UI. Developers interact with a simple form. Behind the scenes, the platform does all the heavy lifting.
* This YAML is processed by the *Scaffolder*, *RHDH*'s templating engine, which executes the steps outlined in the template.
* This ensures that every new service is created in a standerdize, automated , self service way.
* Let‚Äôs examine the structure of a template using 

=== Software Template YAML Structure

* At a basic level, the Template Entity resembles a Kubernetes Custom Resource.
* Where the Template Entity differs is that it contains additional fields: 
. *Header*: Here, you provide essential information about the template.
. *Parameters*: This section is for gathering inputs from the user.
. *Steps*: In this section, you define the actions to be executed by the *Scaffolder*.
. *Output*: This section is optional and allows you to provide details about the tasks performed by the *Scaffolder*.
* Let‚Äôs examine each in more detail.

---

=== Template Header

* The header section is mandatory for every template.
* The *Component* card on the *Create Component* page is displayed based on the details in the Header section.
* For example, this is the header of the link:${gitlab_url}/rhdh/build-secured-dev-workflows-idp-configuration/-/blob/main/scaffolder-templates/quarkus-stssc-template/template.yaml[Software Template,,window=_blank] you will execute in the coming steps:

[source, yaml]
----
apiVersion: scaffolder.backstage.io/v1beta3
kind: Template
metadata:
  name: quarkus-stssc-template
  title: Securing a Quarkus Service Software Supply Chain (Tekton)
  description: Create a Quarkus Service built with Red Hat Trusted Application Pipeline on Tekton
  tags:
    - recommended
    - java
    - quarkus
    - maven
spec:
  owner: tssc
  type: service
  # other fields removed for brevity
----

* The Software Template card is displayed in *RHDH* based on the header information, including the title, description, and tags.

---

===  Template Parameters

* Within the template, the *spec.parameters* field is used to generate the form.
* You can choose to break up the parameter prompting into *form steps* or collect all the parameters in a single step.
* This allows RHDH to generate a wizard like step by step process
* In other words the parameters property is an array, each entry in the array is a *form step*.
* Each form step must specify a *title*, which *properties* it will ask from the user, and if any of them is *required*.
* Following is snippet of te properties section of the Software template you'll execute in the following steps.
* RHDH renders as three steps, each with a seperate form:
. Provide Information for Application
. Provide Image Registry Information
. Application Repository Information
+
[source, yaml]
----
parameters:
    # Parameters can be spread across multiple forms/pages, each
    # with their own titles and set of parameters
    - title: Provide Information for Application
      required:
        - name
        - javaPackageName
      properties:
        name:
          title: Name
          type: string
          description: Unique name of the component
          default: my-quarkus-tkn
          ui:field: EntityNamePicker
          maxLength: 23
         # other fields removed for brevity
    - title: Provide Image Registry Information
      required:
        - imageHost
        - imageOrganization
      properties:
        imageHost:
          title: Image Registry
          type: string
          default: Quay
          enum:
            - Quay
        imageOrganization:
          title: Organization
          type: string
          description: Name of the Quay Organization
          default: tssc
          ui:readonly: true
    - title: Application Repository Information
      required:
        - repoHost
        - repoOwner
        - repoVerifyCommits
      properties:
        repoHost:
          title: Source Repo
          type: string
          default: GitLab
          enum:
            - GitLab
        # other fields removed for brevity
----

---

=== Template Steps

* Steps define the actions that are performed by the *Scaffolder*  during its execution.
* They are executed sequentially as defined in the template.
* Each step utilizes actions for tasks such as publishing to a Gitlab repository (publish:gitlab) or registering a component in the catalog (catalog:register).
* RHDH offers various built-in actions, and you can define custom actions as well.
+
[source, yaml]
----
  steps:
    - id: fetch-provision-data
      name: Fetch Provision Data
      action: catalog:fetch
      input:
        entityRef: component:default/provisioning-data
 	# other steps removed for brevity
    
    - id: publish-gitlab-source
      name: Publish
      action: publish:gitlab
      input:
        repoUrl: 'gitlab-gitlab.${{ steps["fetch-provision-data"].output.entity.metadata.labels["ocp-apps-domain"] }}?owner=${{
          parameters.repoOwner }}&repo=${{parameters.name}}'
        repoVisibility: public
    # other steps removed for brevity
   
    - id: register-source
      name: Register Source
      action: catalog:register
      input:
        repoContentsUrl: ${{ steps['publish-gitlab-source'].output.repoContentsUrl }}
        catalogInfoPath: '/catalog-info.yaml'
    # other steps removed for brevity
----
+ 
* Notice how the parameters are referenced in the input of the steps? 
* Another point of note is that subsequent steps can access output from prior steps.
* To see the available actions in *RHDH* and understand their input and output parameters, go to the *Create Content* page by selecting *Create* from the left sidebar menu.
* Next, open the *Kebab* menu at the top right of the *Create Content* page and choose *Installed Actions*.

=== Template Output

* The spec.output can be used to display useful information such as:
. Links to newly created Components
. Source Code Repository links
. Links to Git Merge Requests that are needed etc

[source, yaml]
----
output:
    links:
      - title: Source Repository
        url: ${{ steps['publish-gitlab-source'].output.remoteUrl }}
      - title: GitOps Repository
        url: ${{ steps['publish-gitlab-gitops'].output.remoteUrl }}
      - title: Open Component in catalog
        icon: catalog
        entityRef: ${{ steps['register-source'].output.entityRef }}
      - title: Open GitOps Resource in catalog
        icon: catalog
        entityRef: ${{ steps['register-gitops'].output.entityRef }}
----

---

== Step 3: Explore Your Quarkus Application

* Evan to provide details here

---

== Step 4: Prepare Developer and Pipeline Trust Foundations

* Before you start modifying code, you need to configure Git commit signing in OpenShift Dev Spaces.
* link:https://developers.redhat.com/products/openshift-dev-spaces[*OpenShift Dev Spaces*,window=_blank] provides cloud-hosted development environments that run inside the cluster. These environments are defined declaratively using link:https://devfile.io/[*Devfiles*,window=_blank], which describe the tools, configuration, and lifecycle behaviour of a developer workspace.
*  You also need to ensure the CI pipelines have the credentials required to authenticate with external systems during the build and verification stages.

=== 4.1 Create the tas-git-config ConfigMap

* In this step, you will configure *Dev Spaces* so that every developer workspace automatically inherits the information required for OIDC-based Git commit signing, without manual setup.

* First, create a new ConfigMap in the openshift-devspaces namespace:

[source, role="execute", subs="attributes"]
----
cat << 'EOF' | oc apply -n openshift-devspaces -f -
apiVersion: v1
kind: ConfigMap
metadata:
  name: tas-git-config
  annotations:
    controller.devfile.io/mount-as: env
  labels:
    app.kubernetes.io/part-of: che.eclipse.org
    app.kubernetes.io/component: workspaces-config
data:
  TAS_FULCIO_URL: "{tas_fulcio_url}"
  TAS_REKOR_URL: "{tas_rekor_url}"
  TAS_ISSUER_URL: "https://sso.{openshift_cluster_ingress_domain}/realms/sso"
  TAS_CLIENT_ID: "trusted-artifact-signer"
EOF
----

* This ConfigMap defines the endpoints and identity configuration required by *gitsign*, the tool used to perform keyless Git commit signing via *RHTAS*.

NOTE: The label app.kubernetes.io/component=workspaces-config instructs Dev Spaces to inject these values into every developer workspace as environment variables.

---

=== *`Optional Deep Dive üîç:`* Development Environment as Code with Devfiles

* The concept of *Development Environment as Code* represents a significant shift in the way we set up and manage development environments. 
* By treating these configurations as code, developers can leverage automation, apply version control, and ensure consistency across various setups. 
* This approach simplifies the complex process of configuring individual environments and aligns it with modern DevOps practices.
* At the heart of this paradigm is the *Devfile*, a powerful YAML configuration file used by **OpenShift Dev Spaces**. 
* *Devfiles* act as comprehensive blueprints for setting up development environments, defining everything from runtime environments to the necessary tools and commands needed for a project.

=== Anatomy of a Devfile

==== Projects (Optional)

* The *Projects* section is used to specify source code repositories that are essential for the development environment. 
* It includes details like the repository URL and the specific branch, tag, or commit to be used, ensuring that the *workspace* is pre-populated with the correct code version upon initialization.

==== Components: 

* *Components* are the building blocks of the development environment. The can be of type:
. *Container*: Defines the container image containing the runtime environment, development tools, and dependencies.
. *Kubernetes/OpenShift Resources*: Incorporates Kubernetes or OpenShift-specific resources such as Routes and BuildConfigs into the workspace.
. *Volume*: Provides persistent storage necessary for certain data within the development environment.
. *Plugin*: Extends the capabilities of the development environment by adding IDE features or integrating additional tools and services.

==== Commands (Optional): 

* The **Commands** section outlines specific actions that can be executed within the development environment, such as build, run, and test commands. 
* These *commands* are defined to automate tasks and facilitate a consistent development workflow across different environments. 
* Each *command* can specify a working directory, an associated container, and the actual command line to execute.

==== Events (Optional): 

* The *Events* section in a *devfile* handles the lifecycle events of the workspace, such as pre-start, post-start, pre-stop, and post-stop events.
* These events trigger specific commands at different stages of the workspace lifecycle, enabling the setup or teardown of services and tools necessary for the development process.
* This mechanism ensures that certain tasks are automatically handled at the appropriate times, enhancing both the efficiency and reliability of the development environment.

image::devfile_anatomy.png[]

* Now it‚Äôs time to try this out hands-on. In this module, you‚Äôll experience firsthand how *OpenShift Dev Spaces* streamlines the process of joining a new project.

---

=== 3.2 Log Back in to GitLab Update the Devfile 

* If you are not already logged in to *RHBK*, click the *Gitlab* tab in the Showroom and log in using:

* *Username*:

[source, role="execute", subs="attributes"]
----
{gitlab_root_user}
----

* *Password*:

[source, role="execute", subs="attributes"]
----
{gitlab_root_password}
----

---

=== 3.3 Update the Devfile 

. At the top left click on Gitlab Home
+
image::gitlab_home_page.png[gitlab_home_page,align="center"]
+
. Select the repository "development / my-quarkus-tkn"
+
image::my-quarkus-tkn_repo.png[gitlab_home_page,align="center"]
+
. Select the the file *devfile.yaml*
+
image::select_devfile.png[select_devfile,align="center"]
+
. Select *Edit* > *Edit single file*.
+
image::devfile_single_edit.png[devfile_single_edit,align="center"]
+
. In devfile.yaml, locate and uncomment the *attribures* section using `CMD + /` (Mac) or `CTRL + /` (Windows/Linux) as shown below: 
** These attributes allow configuration from the ConfigMap you created earlier to be injected into your workspace in OpenShift Dev Spaces.
+
image::dev_tools_atributes.png[dev_tools_atributes,align="center"]
+
. Next, under the commands section, uncomment the *init-git-config* command using using `CMD + /` (Mac) or `CTRL + /` (Windows/Linux) as shown below:  
** This command updates the Git configuration for the current workspace session using the injected environment variables, enabling commit signing.
+
image::init_git_config_command.png[init_git_config_command,align="center"]
+
. Finally, under the events section, uncomment the postStart event using CMD + / (Mac) or CTRL + / (Windows/Linux). 
** This *post-start* event automatically triggers the *init-git-config* command as soon as the workspace starts.
+
image::poststart_Event.png[poststart_Event.png,align="center"]
+
. Scroll down and enter a commit message: 
+
[source, role="execute"]
----
feat: Update Devfile Configuration 
----
+
. Click *Commit Changes* 

---

=== 3.3 Configure pipeline authentication secrets

* Before executing the software template, the CI pipeline must be able to authenticate to the systems it interacts with.
* All application pipelines in this workshop run in the tssc-app-ci namespace. Any credentials required by the pipeline must be available there as Kubernetes Secrets.
* Some secrets are already present:
. rox-api-token: Used by the pipeline to authenticate to ACS and execute roxctl image scan and policy check commands.
. tssc-image-registry-auth: Used to authenticate to the local Quay registry so images can be pushed and pulled during the build and promotion stages.
* In this step, you will create two additional secrets required by the pipeline:
. Credentials for uploading SBOMs to Red Hat Trusted Profile Analyzer (RHTPA)
. Credentials for authenticating to GitLab when creating repositories and interacting with source code
* These secrets are consumed automatically by the pipeline provisioned through the software template.
* Run the following command to set the TPA_SERVER_URL
+
[source,role="execute"]
----
export TPA_SERVER_URL="https://$(oc get route -l app.kubernetes.io/component=server -n tssc-tpa -o json \
  | jq -r '.items[0].spec.host')"
----
+
* Then run this command to create the tpa-secret secret:
+
[source,role="execute"]
----
envsubst < ~/lab-assets/tpa-secret.yml | oc apply -n tssc-app-ci -f -
----
+
* This creates a Kubernetes Secret in the tssc-app-ci namespace containing:
. RHTPA endpoint information
. OIDC client credentials
. Token configuration required by the SBOM upload task
* Create the GitLab authentication secret
* The pipeline also needs access to GitLab in order to:
. Push generated source code
. Interact with repositories created by the software template
* First, retrieve the GitLab personal access token:
+
[source,role="execute"]
----
export GITLAB_TOKEN=$(oc get secret root-user-personal-token -n gitlab -o jsonpath='{.data.token}' | base64 -d)
----
+
* Next, create the GitLab authentication secret:
+
[source,role="execute"]
----
envsubst < ~/lab-assets/gitlab-auth-secret.yml | oc apply -n tssc-app-ci -f -
----
+
* This secret is used by pipeline tasks that interact with GitLab APIs and repositories.
* Credentials are injected at runtime, not hard-coded into pipeline definitions.
* From a platform engineering perspective, this step reinforces an important pattern:
. Pipelines are generic and reusable
. Environment-specific credentials are injected through Kubernetes Secrets
. Developers never handle or manage service credentials directly
* This separation allows the same software template and pipeline definition to be promoted across environments, while authentication details remain centrally managed and rotated by platform teams.
* In the next step, you will make a small code change from within OpenShift Dev Spaces and commit it to Git. 
* This commit will be automatically signed using your OIDC identity.

---

== Step 4: Sign Your Code and Enter the Trusted Supply Chain

* In this step, you will make a small code change from within OpenShift Dev Spaces and commit it to Git. This signed commit will automatically trigger the CI pipeline, carrying your trusted identity into the build and verification stages.

=== 4.1 In OpenShift DevSpaces

* Before you start committing your code, you confirm the Gitsign git config.
* "As you see, our development environment has been configured for Gitsign", you explain.
* Run the below command on the *VS Code* terminal to view the Gitsign global git config:
+
[source, role="execute"]
----
git config --global --list
----

NOTE: You may need to allow paste functionality when prompted by the browser.

image::94_Gitsign_Git_Global_Config.png[]

*	Open src/main/resources/application.properties.
* Make a trivial change (for example, add a comment).
* Open the IDE terminal.

[source, role="execute"]
----
git add .
git commit -m "feat: updated configuration with secure signing"
----



== Step 5: Secure Developer Workflow (Inner Loop)

* This is the frictionless security moment.

=== 5.1 Open the Cloud IDE

* In RHDH, open the Catalog and select my-secure-app.
* Click OpenShift Dev Spaces.
* Log in as user1 if prompted.
* Wait for the workspace to start.

=== 5.2 Make a Change

*	Open src/main/resources/application.properties.
* Make a trivial change (for example, add a comment).
* Open the IDE terminal.

[source, role="execute"]
----
git add .
git commit -m "feat: updated configuration with secure signing"
----

Observation:
. You are prompted to authenticate via an OIDC browser flow.
. The login redirects to your Keycloak, not the public Sigstore service.
. After authentication, the commit is signed automatically.

[source, role="execute"]
----
git push origin main
----

* Return to RHDH ‚Üí CI tab.
* A new pipeline run is triggered.
* The pipeline automatically:
. verifies the commit signature,
. builds the image,
. scans it with ACS,
. signs the image with TAS.

== Step 1: Analyse the Dev Build (Security Audit)

Before promoting anything, review the evidence produced by the pipeline in Module 3.
This evidence is what the Enterprise Contract will later enforce.

1.1 Inspect the Pipeline Run
	1.	Open Red Hat Developer Hub (RHDH).
	2.	Select your component (for example, my-secure-app) from the Catalog.
	3.	Click the CI tab and locate the pipeline run triggered in Module 3.
The status should be Succeeded.

‚∏ª

1.2 Review the Security Artifacts

Expand the pipeline run and highlight the following steps:
	‚Ä¢	acs-image-scan
The image was scanned by Red Hat Advanced Cluster Security (RHACS) during the build.
	‚Ä¢	sbom-json / upload-sbom
An SBOM was generated and uploaded to RHTPA (Module 1).
	‚Ä¢	sign-image
The image was signed using an OIDC identity and recorded in Rekor (Module 2).

Consultant deep dive ‚Äì the invisible security officer:
The developer did not run scans, manage keys, or make security decisions.
The pipeline definition, owned by the platform team, enforced these controls automatically.
If a critical policy violation had occurred, the pipeline would have failed before the image was ever published.

‚∏ª

Step 2: Trigger the Release (Developer Action)

Now simulate a developer indicating that the code is ready for release.

2.1 Access the Source Repository
	1.	In RHDH, stay on the component Overview tab.
	2.	Click View Source to open the GitLab repository.
	3.	Log in to GitLab if prompted.

‚∏ª

2.2 Create a Release Tag
	1.	In GitLab, navigate to Code ‚Üí Tags (or use the + menu).
	2.	Click New Tag.
	3.	Set:
	‚Ä¢	Tag name: v1.0 (or prod-rc-1)
	‚Ä¢	Create from: main
	4.	Click Create tag.

What just happened:
The Golden Path template configured a webhook that treats tags differently from commits.
Creating a tag triggers a release pipeline, not the standard development pipeline.

‚∏ª

Step 3: Enterprise Contract Gate (Operations View)

Return to RHDH to observe automated policy enforcement.

3.1 Observe the Release Pipeline
	1.	Navigate back to the CI tab.
	2.	A new PipelineRun should appear (for example, release-pipeline-‚Ä¶).
	3.	Click into the pipeline to follow its progress.

‚∏ª

3.2 Inspect the verify-enterprise-contract Task

This is the critical control point.
	1.	Wait for the verify-enterprise-contract task to reach Succeeded.
	2.	Click the task and review the logs.

What EC validates:
	1.	Provenance: Was the image built by a trusted pipeline?
	2.	Identity: Does the signature match the expected OIDC issuer and subject?
	3.	Integrity: Is the SLSA attestation valid and untampered?



‚∏ª

Step 4: GitOps Promotion (Platform View)

Once policy passes, promotion happens automatically through GitOps.

4.1 Verify Argo CD State
	1.	In RHDH, open the CD tab.
	2.	Observe the Argo CD applications (for example, my-app-dev, my-app-stage).
	3.	Confirm that my-app-stage is syncing or has synced to the new image tag.

‚∏ª

4.2 Verify the Application Topology
	1.	Click the Topology tab in RHDH.
	2.	Confirm the application is now running in the Staging namespace.

‚∏ª

Troubleshooting: Enterprise Contract Failure

If the verify-enterprise-contract task fails:
	1.	Review the task logs.
	2.	Common cause: OIDC issuer or subject mismatch.
	3.	Resolution: Update the Enterprise Contract policy to match the signing identity configured in Module 2.

‚∏ª

Module 4 Takeaway
	‚Ä¢	In this module, you addressed the final customer challenge: enforcing policy consistently without slowing delivery.
	‚Ä¢	As a consultant, you demonstrated automated governance using Enterprise Contract and GitOps-based promotion.
	‚Ä¢	For customers, this means releases are approved by policy, not process. No spreadsheets, no manual gates, no trust assumptions.
	‚Ä¢	For technical sellers, this completes the story: RHADS enforces trust from commit to production, automatically and at scale.

Final customer message:
‚ÄúWith RHADS, you move fast because the platform verifies trust for you, and you stay safe because policy guarantees only verified software reaches production.‚Äù